{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEI0jTK9-VfL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rxEc_HuUUYA4"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.corpus import treebank\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AEXw0n--VfS"
      },
      "source": [
        "# Datasets download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O4WyhH9WL2f",
        "outputId": "4c0eb8ff-729a-4cc1-af04-c0fb391b45e1",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLvYuhRs-VfV"
      },
      "source": [
        "# Tagged sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3GYqC2mfUj_S"
      },
      "outputs": [],
      "source": [
        "tagged_sentences = treebank.tagged_sents()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tagged sentences: {len(tagged_sentences)}\")\n",
        "print(f\"Tagged words: {len(nltk.corpus.treebank.tagged_words())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClUoI_lNK2wM",
        "outputId": "25d0c3cd-867b-418a-d461-0819d5659f6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagged sentences: 3914\n",
            "Tagged words: 100676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(tagged_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbwalI9rK73D",
        "outputId": "687a44bc-2947-4bde-cca2-d607f8270e89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NNP'),\n",
            " ('Vinken', 'NNP'),\n",
            " (',', ','),\n",
            " ('61', 'CD'),\n",
            " ('years', 'NNS'),\n",
            " ('old', 'JJ'),\n",
            " (',', ','),\n",
            " ('will', 'MD'),\n",
            " ('join', 'VB'),\n",
            " ('the', 'DT'),\n",
            " ('board', 'NN'),\n",
            " ('as', 'IN'),\n",
            " ('a', 'DT'),\n",
            " ('nonexecutive', 'JJ'),\n",
            " ('director', 'NN'),\n",
            " ('Nov.', 'NNP'),\n",
            " ('29', 'CD'),\n",
            " ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNsWh63W-VfW"
      },
      "source": [
        "# Sample for output of your PoS tagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlBIyChncJIZ",
        "outputId": "377efd57-245c-4743-fde5-01d5171a2c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT'),\n",
            " ('is', 'VBZ'),\n",
            " ('my', 'PRP$'),\n",
            " ('friend', 'NN'),\n",
            " (',', ','),\n",
            " ('John', 'NNP'),\n",
            " ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(pos_tag(word_tokenize('This is my friend, John.')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extractor"
      ],
      "metadata": {
        "id": "osl32mmMLEKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extractor(sentence, index):\n",
        "    return {\n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'prefix-3': sentence[index][:3],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'suffix-3': sentence[index][-3:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'has_hyphen': '-' in sentence[index],\n",
        "        'is_numeric': sentence[index].isdigit(),\n",
        "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
        "    }  "
      ],
      "metadata": {
        "id": "o-eZOPj7A-5U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(feature_extractor(['This', 'is', 'a', 'sentence'], 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NUzyCsUCmVP",
        "outputId": "85422c3f-b5cb-4fb0-d365-ca68c77b3c7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'capitals_inside': False,\n",
            " 'has_hyphen': False,\n",
            " 'is_all_caps': False,\n",
            " 'is_all_lower': True,\n",
            " 'is_capitalized': False,\n",
            " 'is_first': False,\n",
            " 'is_last': False,\n",
            " 'is_numeric': False,\n",
            " 'next_word': 'sentence',\n",
            " 'prefix-1': 'a',\n",
            " 'prefix-2': 'a',\n",
            " 'prefix-3': 'a',\n",
            " 'prev_word': 'is',\n",
            " 'suffix-1': 'a',\n",
            " 'suffix-2': 'a',\n",
            " 'suffix-3': 'a',\n",
            " 'word': 'a'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "ryVFyStZLL8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def untag(tagged_sentence):\n",
        "    return [w for w, t in tagged_sentence]"
      ],
      "metadata": {
        "id": "mIn5QHqJCoKu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_dataset(tagged_sentences):\n",
        "    X = []\n",
        "    y = []\n",
        "    for tagged in tagged_sentences:\n",
        "        for index in range(len(tagged)):\n",
        "            X.append(feature_extractor(untag(tagged), index))\n",
        "            y.append(tagged[index][1])\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "7NtCXdWjLXsJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SPLIT = 0.8\n",
        "part = int(TRAIN_SPLIT * len(tagged_sentences))\n",
        "training_sentences = tagged_sentences[:part]\n",
        "test_sentences = tagged_sentences[part:]"
      ],
      "metadata": {
        "id": "JK4zS1ILDBAV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of train sentences: {len(training_sentences)}\")\n",
        "print(f\"Number of test sentences: {len(test_sentences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ZA5jowPBHc",
        "outputId": "20a53c08-2bec-4411-8c21-a67f9f5447d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train sentences: 3131\n",
            "Number of test sentences: 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = transform_to_dataset(training_sentences)\n",
        "X_test, y_test = transform_to_dataset(test_sentences)"
      ],
      "metadata": {
        "id": "pHN6jZB1DWLI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length X_train: {len(X_train)}\")\n",
        "print(f\"Length X_test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUoYxrazPm32",
        "outputId": "e1e08998-d6ac-48cb-c0cd-a98c1fe3206b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length X_train: 80637\n",
            "Length X_test: 20039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_vectorizer = DictVectorizer(sparse=False)\n",
        "dict_vectorizer.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIig5upvDrwj",
        "outputId": "1e5509bf-b443-4931-d280-7e3d6065ff4d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(sparse=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and training"
      ],
      "metadata": {
        "id": "KsOg42-7LoQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Pipeline([\n",
        "    ('vectorizer', DictVectorizer(sparse=False)),\n",
        "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
        "]) "
      ],
      "metadata": {
        "id": "o37swWfzDza7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_TRAIN = 10000\n",
        "classifier.fit(X_train[:N_TRAIN], y_train[:N_TRAIN])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po6FEB1wEEH6",
        "outputId": "9d82d1f6-c808-490c-a0bf-44b7f4a7b537"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', DictVectorizer(sparse=False)),\n",
              "                ('classifier', DecisionTreeClassifier(criterion='entropy'))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "Wka6lUH3LdSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = classifier.score(X_train, y_train)\n",
        "print(f\"Train Accuracy: {train_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It8pboFwLhC-",
        "outputId": "2d69fb34-60a0-4f7f-b80c-c6919b4867f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8949489688356461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = classifier.score(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_vnuTNwEeVG",
        "outputId": "8b1360aa-d87d-4ec4-9096-2959963d1ab0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8933579519936125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model output"
      ],
      "metadata": {
        "id": "HEEc1WgFLvkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_pos_tag(sentence, clf):\n",
        "    tags = clf.predict([feature_extractor(sentence, index) for index in range(len(sentence))])\n",
        "    return list(zip(sentence, tags))"
      ],
      "metadata": {
        "id": "R5bZN7hIEt2M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_sentence = 'This is my friend, John.'\n",
        "my_tagged_sentence = my_pos_tag(word_tokenize(my_sentence), classifier)"
      ],
      "metadata": {
        "id": "KuM1AGQiE7EI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(my_tagged_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th5ftwb_M-aa",
        "outputId": "f7c30c2f-0691-4267-b943-d4f7e729f085"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT'),\n",
            " ('is', 'VBZ'),\n",
            " ('my', 'NN'),\n",
            " ('friend', 'NN'),\n",
            " (',', ','),\n",
            " ('John', 'NNP'),\n",
            " ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "Ck0fRsysOeAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Ai POS-(parts_of_speech) tagger #PART-1](https://medium.datadriveninvestor.com/ai-pos-parts-of-speech-tagger-part-1-a3d6bd77ce5e)"
      ],
      "metadata": {
        "id": "mAB-ZtbVOlGh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "PoS_Tagger.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}